{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Models\n",
    "\n",
    "This notebook explores the different possibilities of embbedding models we may use in the project. The code implementing these models can be found in `/src/embedders` and are imported into this notebook.\n",
    "\n",
    "This document will go over each embedding model, talk about how it works and its potential strengths/weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import sys and use it to add the root of the project to the path to import from src\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "\n",
    "# Necessary imports for basic similarity calculation\n",
    "from sentence_transformers import util\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Embedders\n",
    "from src.embedders import CountEmbeddor, TFIDFEmbeddor, BERTEmbeddor, SentenceTransformerEmbeddor, EmbeddorBase\n",
    "from src import utils\n",
    "\n",
    "# Reloading of embedders when the file changes\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport src.embedders\n",
    "%aimport src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare each embedder\n",
    "models: list[EmbeddorBase] = [\n",
    "    CountEmbeddor(),\n",
    "    TFIDFEmbeddor(),\n",
    "    BERTEmbeddor(),\n",
    "    SentenceTransformerEmbeddor(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see how the embedders work on a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>CountEmbeddor</th>\n",
       "      <th>TFIDFEmbeddor</th>\n",
       "      <th>BERTEmbeddor</th>\n",
       "      <th>SentenceTransformerEmbeddor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The beer is nice, with sweet nutty flavours</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.19880075548313855, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[-0.13595613837242126, -0.12485707551240921, 0...</td>\n",
       "      <td>[-0.03745955228805542, -0.04137440770864487, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a very different sentence</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4712248263552...</td>\n",
       "      <td>[-0.4844885468482971, -0.45589154958724976, 0....</td>\n",
       "      <td>[0.063898965716362, 0.035758040845394135, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not sweet enough. I like my beer sweet.</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.2218918546331659, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.1911739706993103, 0.1460820585489273, 0.283...</td>\n",
       "      <td>[-0.010137715376913548, -0.03818701580166817, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not sweet at all. Terrible beer.</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0.45028691074908056, 0.45028691074908056, 0.2...</td>\n",
       "      <td>[-0.46719881892204285, 0.5336718559265137, -0....</td>\n",
       "      <td>[-0.018374629318714142, -0.0001956572814378887...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not sweet at all. But I like bitter beers so i...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, ...</td>\n",
       "      <td>[0.2724910606076718, 0.2724910606076718, 0.155...</td>\n",
       "      <td>[-0.2824631333351135, 0.30220910906791687, 0.1...</td>\n",
       "      <td>[-0.025126323103904724, -0.04645886644721031, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0        The beer is nice, with sweet nutty flavours   \n",
       "1                  This is a very different sentence   \n",
       "2           Not sweet enough. I like my beer sweet.    \n",
       "3                  Not sweet at all. Terrible beer.    \n",
       "4  Not sweet at all. But I like bitter beers so i...   \n",
       "\n",
       "                                       CountEmbeddor  \\\n",
       "0  [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, ...   \n",
       "3  [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, ...   \n",
       "\n",
       "                                       TFIDFEmbeddor  \\\n",
       "0  [0.0, 0.0, 0.19880075548313855, 0.0, 0.0, 0.0,...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4712248263552...   \n",
       "2  [0.0, 0.0, 0.2218918546331659, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.45028691074908056, 0.45028691074908056, 0.2...   \n",
       "4  [0.2724910606076718, 0.2724910606076718, 0.155...   \n",
       "\n",
       "                                        BERTEmbeddor  \\\n",
       "0  [-0.13595613837242126, -0.12485707551240921, 0...   \n",
       "1  [-0.4844885468482971, -0.45589154958724976, 0....   \n",
       "2  [0.1911739706993103, 0.1460820585489273, 0.283...   \n",
       "3  [-0.46719881892204285, 0.5336718559265137, -0....   \n",
       "4  [-0.2824631333351135, 0.30220910906791687, 0.1...   \n",
       "\n",
       "                         SentenceTransformerEmbeddor  \n",
       "0  [-0.03745955228805542, -0.04137440770864487, 0...  \n",
       "1  [0.063898965716362, 0.035758040845394135, 0.01...  \n",
       "2  [-0.010137715376913548, -0.03818701580166817, ...  \n",
       "3  [-0.018374629318714142, -0.0001956572814378887...  \n",
       "4  [-0.025126323103904724, -0.04645886644721031, ...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe with some sample reviews\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": [\n",
    "            \"The beer is nice, with sweet nutty flavours\",\n",
    "            \"This is a very different sentence\",\n",
    "            \"Not sweet enough. I like my beer sweet. \",\n",
    "            \"Not sweet at all. Terrible beer. \",\n",
    "            \"Not sweet at all. But I like bitter beers so it is a nice beer. \",\n",
    "            \"Piss yellow beer\",\n",
    "            \"Sweet beer\"\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Loop through each model and add the embeddings to the dataframe\n",
    "for model in models:\n",
    "    df[model.name] = model.transform(df[\"text\"]).tolist()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go over how each one works.\n",
    "\n",
    "- CountEmbeddors uses sklearn's [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). Count vectorisation simply assigns each word in the vocabulary to a variable in the feature vector, and the values are the counts of each word. \n",
    "\n",
    "- TFIDF is similar to CountVectorizer, but also multiplies by an 'inverse document frequency' term. This weights a word in the vocabular by how frequently it appears in the corpus. Very common words are penalised, and rarer words are given more weight. This also uses sklearn's [TFIDFVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n",
    "\n",
    "*NB: Unlike the the other embeddors, both CountEmbedders and TFIDF require the **entire** string of reviews to be passed at once in their current implementation. You cannot pass in reviews separately, since the feature vector must fit to the entire vocabulary before transforming any reviews. This could be changed in future by passing in a length of reviews into the constructor of the embeddors for fitting, and transforming only when called. However, given that these models are simple and fast, this doesn't feel necessary.*\n",
    "\n",
    "- BERTEmbeddor uses `bert-base-uncased` [from HuggingFace](https://huggingface.co/bert-base-uncased). BERT is a bidirectional encoder-only transformer. There are many options for extracting embeddings from the model since there are 12 layers, and an embbedding for each token input. Currently, the implementation takes the penultimate hidden state of the model and takes the mean across all tokens in the input (see [this guide](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/)).\n",
    "\n",
    "- SentenceTransformerEmbeddor uses the recommended `all-MiniLM-L6-v2` model from the `sentence-transformers` [library]((https://www.sbert.net/docs/pretrained_models.html)). These models take outputs from BERT, conduct pooling similar to above (e.g. by default, mean of last layer), and are trained on various sentence-related NLP problems using [Siamese networks](https://towardsdatascience.com/a-friendly-introduction-to-siamese-networks-85ab17522942)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the models' behaviour with desired behaviour using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts: \n",
      "The beer is nice, with sweet nutty flavours\n",
      "This is a very different sentence\n",
      "Not sweet enough. I like my beer sweet. \n",
      "Not sweet at all. Terrible beer. \n",
      "Not sweet at all. But I like bitter beers so it is a nice beer. \n",
      "Piss yellow beer\n",
      "Sweet beer\n",
      "\n",
      "Similarity between first and nth sentence:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity 2</th>\n",
       "      <th>Similarity 3</th>\n",
       "      <th>Similarity 4</th>\n",
       "      <th>Similarity 5</th>\n",
       "      <th>Similarity 6</th>\n",
       "      <th>Similarity 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CountEmbeddor</th>\n",
       "      <td>0.158114</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.392232</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFIDFEmbeddor</th>\n",
       "      <td>0.087044</td>\n",
       "      <td>0.224413</td>\n",
       "      <td>0.170776</td>\n",
       "      <td>0.248458</td>\n",
       "      <td>0.116718</td>\n",
       "      <td>0.379978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERTEmbeddor</th>\n",
       "      <td>0.617567</td>\n",
       "      <td>0.791830</td>\n",
       "      <td>0.791252</td>\n",
       "      <td>0.828123</td>\n",
       "      <td>0.721489</td>\n",
       "      <td>0.776372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SentenceTransformerEmbeddor</th>\n",
       "      <td>0.094767</td>\n",
       "      <td>0.667616</td>\n",
       "      <td>0.699760</td>\n",
       "      <td>0.718871</td>\n",
       "      <td>0.334227</td>\n",
       "      <td>0.650784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Similarity 2  Similarity 3  Similarity 4  \\\n",
       "CountEmbeddor                    0.158114      0.353553      0.288675   \n",
       "TFIDFEmbeddor                    0.087044      0.224413      0.170776   \n",
       "BERTEmbeddor                     0.617567      0.791830      0.791252   \n",
       "SentenceTransformerEmbeddor      0.094767      0.667616      0.699760   \n",
       "\n",
       "                             Similarity 5  Similarity 6  Similarity 7  \n",
       "CountEmbeddor                    0.392232      0.204124      0.500000  \n",
       "TFIDFEmbeddor                    0.248458      0.116718      0.379978  \n",
       "BERTEmbeddor                     0.828123      0.721489      0.776372  \n",
       "SentenceTransformerEmbeddor      0.718871      0.334227      0.650784  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_similarity(review1: str, review2: str) -> float:\n",
    "    \"\"\"Computes the similarity between two reviews using all the models\"\"\"\n",
    "    texts = [review1, review2]\n",
    "    similarities = {}\n",
    "    for model in models:\n",
    "        embeddings = model.transform(texts).tolist()\n",
    "        similarities[model.name] = util.cos_sim(\n",
    "            torch.Tensor(embeddings[0]), torch.Tensor(embeddings[1])\n",
    "        ).item()\n",
    "    return similarities\n",
    "\n",
    "df_methods = pd.DataFrame(index=[model.name for model in models])\n",
    "\n",
    "# Compute the similarity between the first and the nth sentence\n",
    "for i in range(1, len(df)):\n",
    "    df_methods[\"Similarity \" + str(i+1)] = get_similarity(df[\"text\"][0], df[\"text\"][i]).values()\n",
    "\n",
    "print(\"Texts: \\n\" + \"\\n\".join(df[\"text\"].values.tolist()))\n",
    "print(\"\\nSimilarity between first and nth sentence:\")\n",
    "df_methods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the obvious pitfall of using count-vectorizer and tf-idf - they lose all context. If, during the pipeline, we were to group beers by some measure that affects their sweetness, then in order to confirm out hypothesis we would like to see an increase of similarity inside each group, but we may lower similarity due to negations.\n",
    "\n",
    "However, BERT and SentenceTransformers are not necessarily better. The values are far less interpretable, with sentence embeddor falling for a similar negation trap. Interestingly, SentenceTransformer was far better than BERT at differentiating between sentences on different topic matters - but it dealt with negation interestingly. Perhaps with many descriptors sentence-transformer would do very well. BERT's scores are all broadly similar, it roughly gets it right, but I have little faith that this translates any better than sentence transformer to the real reviews.\n",
    "\n",
    "However, for now, I think tf-idf is our best shot. It is the most interpretable (we can get out the most impactful words at the end), and if there are enough reviews are long enough, we should see a meaningful vocabulary emerge. If the tfidf embeddings seem to be limiting us in the future, we can experiment further with other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try with some real sample reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"../data\")\n",
    "\n",
    "sample_reviews = utils.load_data(DATA_DIR, num_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From a bottle, pours a piss yellow color with a fizzy white head.  This is carbonated similar to soda.The nose is basic.. malt, corn, a little floral, some earthy straw.  The flavor is boring, not offensive, just boring.  Tastes a little like corn and grain.  Hard to write a review on something so simple.Its ok, could be way worse.\n",
      "Pours pale copper with a thin head that quickly goes. Caramel, golden syrup nose. Taste is big toasty, grassy hops backed by dark fruit, candy corn and brack malts. Clingy. Dries out at the end with more hops. Brave, more going on that usual for this type.\n",
      "500ml Bottle bought from The Vintage, Antrim...Poured a golden yellow / orange colour... White head poured quite thick and foamy and faded to thin layer...Aroma - Fruity (burnt orange, some apple hints), light maltiness, spicy hops, vanilla, some sea saltiness...Taste - Spicy / peppery hop notes, citrusy, light sweetness, grassy, slight creaminess, some bready notes...Feel - Quite sharp and pretty dry. Light body.... Pretty drinkable...Overall - A pretty good beer.... worth a try...\n",
      "Serving: 500ml brown bottlePour: Good head with excellent retention and a slight amount of lacing Appearance: Slightly cloudy golden colour. Smell: Very subtle sweet smell, nothing too distinct comes throughFlavour: Subtle bitter flavour, slight taste of fresh hay. Nice hoppy flavours. Like the smell, no real distinct flavours come through. Overall: Quite a refreshing brew. Nicely balanced. Nice to see a local brewery producing quality beers like this one and long may it continue! Looking forward to trying more of Strangfords brews.\n",
      "Embeddings:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>CountEmbeddor</th>\n",
       "      <th>TFIDFEmbeddor</th>\n",
       "      <th>BERTEmbeddor</th>\n",
       "      <th>SentenceTransformerEmbeddor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From a bottle, pours a piss yellow color with ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.07052336179037168, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[-0.09374433755874634, 0.11626264452934265, 0....</td>\n",
       "      <td>[-0.02019408345222473, -0.056765299290418625, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pours pale copper with a thin head that quickl...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0805288704304574, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.32329174876213074, 0.22151388227939606, 0....</td>\n",
       "      <td>[-0.03042781352996826, -0.047437869012355804, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500ml Bottle bought from The Vintage, Antrim.....</td>\n",
       "      <td>[1, 0, 3, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0.08614715820209162, 0.0, 0.1710597639733336,...</td>\n",
       "      <td>[-0.5143056511878967, -0.01398462150245905, 0....</td>\n",
       "      <td>[-0.01840173825621605, -0.04508772864937782, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Serving: 500ml brown bottlePour: Good head wit...</td>\n",
       "      <td>[1, 1, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0.08193284252694036, 0.10392142170524836, 0.1...</td>\n",
       "      <td>[-0.33155936002731323, 0.016586432233452797, 0...</td>\n",
       "      <td>[-0.006383390631526709, -0.05744396895170212, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  From a bottle, pours a piss yellow color with ...   \n",
       "1  Pours pale copper with a thin head that quickl...   \n",
       "2  500ml Bottle bought from The Vintage, Antrim.....   \n",
       "3  Serving: 500ml brown bottlePour: Good head wit...   \n",
       "\n",
       "                                       CountEmbeddor  \\\n",
       "0  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...   \n",
       "1  [0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, ...   \n",
       "2  [1, 0, 3, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "3  [1, 1, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, ...   \n",
       "\n",
       "                                       TFIDFEmbeddor  \\\n",
       "0  [0.0, 0.0, 0.07052336179037168, 0.0, 0.0, 0.0,...   \n",
       "1  [0.0, 0.0, 0.0805288704304574, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.08614715820209162, 0.0, 0.1710597639733336,...   \n",
       "3  [0.08193284252694036, 0.10392142170524836, 0.1...   \n",
       "\n",
       "                                        BERTEmbeddor  \\\n",
       "0  [-0.09374433755874634, 0.11626264452934265, 0....   \n",
       "1  [-0.32329174876213074, 0.22151388227939606, 0....   \n",
       "2  [-0.5143056511878967, -0.01398462150245905, 0....   \n",
       "3  [-0.33155936002731323, 0.016586432233452797, 0...   \n",
       "\n",
       "                         SentenceTransformerEmbeddor  \n",
       "0  [-0.02019408345222473, -0.056765299290418625, ...  \n",
       "1  [-0.03042781352996826, -0.047437869012355804, ...  \n",
       "2  [-0.01840173825621605, -0.04508772864937782, 0...  \n",
       "3  [-0.006383390631526709, -0.05744396895170212, ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = sample_reviews['review']['text'].tolist()\n",
    "\n",
    "print(\"\\n\".join(reviews))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": reviews\n",
    "    }\n",
    ")\n",
    "\n",
    "# Loop through each model and add the embeddings to the dataframe\n",
    "for model in models:\n",
    "    df[model.name] = model.transform(df[\"text\"]).tolist()\n",
    "print(\"Embeddings:\")\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts: \n",
      "From a bottle, pours a piss yellow color with a fizzy white head.  This is carbonated similar to soda.The nose is basic.. malt, corn, a little floral, some earthy straw.  The flavor is boring, not offensive, just boring.  Tastes a little like corn and grain.  Hard to write a review on something so simple.Its ok, could be way worse.\n",
      "Pours pale copper with a thin head that quickly goes. Caramel, golden syrup nose. Taste is big toasty, grassy hops backed by dark fruit, candy corn and brack malts. Clingy. Dries out at the end with more hops. Brave, more going on that usual for this type.\n",
      "500ml Bottle bought from The Vintage, Antrim...Poured a golden yellow / orange colour... White head poured quite thick and foamy and faded to thin layer...Aroma - Fruity (burnt orange, some apple hints), light maltiness, spicy hops, vanilla, some sea saltiness...Taste - Spicy / peppery hop notes, citrusy, light sweetness, grassy, slight creaminess, some bready notes...Feel - Quite sharp and pretty dry. Light body.... Pretty drinkable...Overall - A pretty good beer.... worth a try...\n",
      "Serving: 500ml brown bottlePour: Good head with excellent retention and a slight amount of lacing Appearance: Slightly cloudy golden colour. Smell: Very subtle sweet smell, nothing too distinct comes throughFlavour: Subtle bitter flavour, slight taste of fresh hay. Nice hoppy flavours. Like the smell, no real distinct flavours come through. Overall: Quite a refreshing brew. Nicely balanced. Nice to see a local brewery producing quality beers like this one and long may it continue! Looking forward to trying more of Strangfords brews.\n",
      "Similarity between first and nth sentence:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity 2</th>\n",
       "      <th>Similarity 3</th>\n",
       "      <th>Similarity 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CountEmbeddor</th>\n",
       "      <td>0.242251</td>\n",
       "      <td>0.175406</td>\n",
       "      <td>0.149150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFIDFEmbeddor</th>\n",
       "      <td>0.143139</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.082265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERTEmbeddor</th>\n",
       "      <td>0.932061</td>\n",
       "      <td>0.887740</td>\n",
       "      <td>0.883530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SentenceTransformerEmbeddor</th>\n",
       "      <td>0.644700</td>\n",
       "      <td>0.596318</td>\n",
       "      <td>0.472954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Similarity 2  Similarity 3  Similarity 4\n",
       "CountEmbeddor                    0.242251      0.175406      0.149150\n",
       "TFIDFEmbeddor                    0.143139      0.100011      0.082265\n",
       "BERTEmbeddor                     0.932061      0.887740      0.883530\n",
       "SentenceTransformerEmbeddor      0.644700      0.596318      0.472954"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_methods = pd.DataFrame(index=[model.name for model in models])\n",
    "\n",
    "# Compute the similarity between the first and the nth sentence\n",
    "for i in range(1, len(df)):\n",
    "    df_methods[\"Similarity \" + str(i+1)] = get_similarity(df[\"text\"][0], df[\"text\"][i]).values()\n",
    "\n",
    "print(\"Texts: \\n\" + \"\\n\".join(df[\"text\"].values.tolist()))\n",
    "print(\"Similarity between first and nth sentence:\")\n",
    "df_methods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the metrics agree on the ordering of similarity - which is a good sign. BERT is the least sure, with very high values, as in the previous example. The other 3 are pretty much the same but at different magnitudes.\n",
    "\n",
    "Reading the reviews, it's very hard to define what the ordering *should* be."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
