{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretability\n",
    "\n",
    "This file contains exploration for the part of our datastory concering mapping out the precise differences in lexicon between groups of beers. The philosophy centres on the idea that to be a beer 'connoisseur', you need to use the words that are attirbuted to particular beer characteristics. We first look at the overall lexicon, but this only provides a guide for all beers. To provide beer-specific vocabulary, we look at a group of beers, say IPA, and look at the words used to describe these beers versus other kinds of beers. The biggest (relevant) differences can be interpreted as the words which should be used to describe that group.\n",
    "\n",
    "We first look at the lexicon for all beers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# Enable continuous module reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport src\n",
    "\n",
    "# Standard library\n",
    "import os\n",
    "import math\n",
    "\n",
    "# External library\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# NLP library\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Seaborn config\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette(\"dark\")\n",
    "\n",
    "# Custom modules\n",
    "from src import utils\n",
    "from src import extractors\n",
    "from src import embedders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "print(DATA_DIR)\n",
    "\n",
    "# Random seed\n",
    "SEED = 42\n",
    "\n",
    "# Subsetting options\n",
    "SUBSET = True\n",
    "NUM_SUBSET_SAMPLES = 1_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all reviews and a subset of reviews (100,000)\n",
    "if SUBSET:\n",
    "    reviews = utils.load_data(DATA_DIR, num_samples=NUM_SUBSET_SAMPLES, seed=SEED)\n",
    "else:\n",
    "    reviews = utils.load_data(DATA_DIR, seed=SEED)\n",
    "\n",
    "msg = \"Subset of Data\" if SUBSET else \"Full Data\"\n",
    "print(f\"Loaded {len(reviews)} reviews âœ…. ({msg})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_reviews = [nlp(text) for text in tqdm(reviews.review.text.tolist())]\n",
    "reviews[(\"review\", \"docs\")] = processed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjective_extractor = extractors.AdjectiveExtractor()\n",
    "embedder = embedders.TfidfEmbedder()\n",
    "\n",
    "# reviews[('review', 'adjectives')] = adjective_extractor.transform(reviews[('review', 'docs')])\n",
    "# reviews[('review', 'embedding')] = embedder.transform(reviews[('review', 'adjectives')]).tolist()\n",
    "\n",
    "# Use only stopword removal\n",
    "reviews[('review', 'no_stopwords')] = reviews[('review', 'docs')].apply(lambda doc: \n",
    "                                          \" \".join(token.lemma_ for token in doc\n",
    "                                                   if not token.is_stop))\n",
    "print(reviews[('review', 'no_stopwords')].head())\n",
    "reviews[('review', 'embedding')] = embedder.transform(reviews[('review', 'no_stopwords')]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_embedding = np.array(reviews[('review', 'embedding')].tolist()).mean(axis=0)\n",
    "\n",
    "top_k = 10\n",
    "top_k_embeddings = np.argsort(average_embedding)[::-1][:top_k]\n",
    "top_k_features = np.array(embedder.get_feature_names())[top_k_embeddings]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "sns.barplot(y=top_k_features, x=average_embedding[top_k_embeddings], ax=ax, orient=\"h\", color=\"r\")\n",
    "ax.set_title(f\"Top {top_k} Features across all Reviews\")\n",
    "ax.set_xlabel(\"Feature\")\n",
    "ax.set_ylabel(\"Average Embedding\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "average_embedding_df = pd.DataFrame(average_embedding, index=embedder.get_feature_names(), columns=[\"embedding\"])\n",
    "average_embedding_df.sort_values(\"embedding\", ascending=False, inplace=True)\n",
    "average_embedding_df.head(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We now look at differences in vocabular when reviewing a particular beer.\n",
    "\n",
    "To do this, we first look at the TFIDF average embbedding of a particular subgroup and compare them with the average embedding of the entire group (minus the subgroup). We look at maximum differences between these two sets of embeddings.\n",
    "\n",
    "We then use an SVM to train a classifier on these differences, which takes into account the distributions rather than just looking at the averages. We can then find the largest coefficients of this model and use these as the most important features to discern between the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = reviews[('beer', 'style')].unique()\n",
    "n_styles = 6\n",
    "\n",
    "# Plot the top 10 features for each style\n",
    "rows = math.ceil(n_styles / 3)\n",
    "cols = 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(8 * rows, 3 * cols))\n",
    "\n",
    "for i, style in enumerate(styles[:n_styles]):\n",
    "    style_reviews = reviews[reviews[('beer', 'style')] == style]\n",
    "    print(f\"Found {len(style_reviews)} reviews for {style}\")\n",
    "    style_embedding = np.array(style_reviews[('review', 'embedding')].tolist()).mean(axis=0)\n",
    "    top_k_embeddings = np.argsort(style_embedding)[::-1][:top_k]\n",
    "    top_k_features = np.array(embedder.get_feature_names())[top_k_embeddings]\n",
    "    ax = axes[i //3, i%3]\n",
    "    sns.barplot(y=top_k_features, x=style_embedding[top_k_embeddings], ax=ax, orient=\"h\", color=\"r\")\n",
    "    ax.set_title(f\"{style}\")\n",
    "    ax.set_xlabel(\"Feature\")\n",
    "    ax.set_ylabel(\"Average Embedding\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at a specific subgroup - say English Bitters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = reviews[('beer', 'style')].unique()\n",
    "n_styles = 6\n",
    "\n",
    "# Plot the top 10 features for each style\n",
    "rows = math.ceil(n_styles / 3)\n",
    "cols = 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(8 * rows, 3 * cols))\n",
    "\n",
    "for i, style in enumerate(styles[:n_styles]):\n",
    "    style_reviews = reviews[reviews[('beer', 'style')] == style]\n",
    "    rest_reviews = reviews[reviews[('beer', 'style')] != style]\n",
    "    print(f\"Found {len(style_reviews)} reviews for {style} of the {len(reviews)} total reviews\")\n",
    "\n",
    "    style_embedding = np.array(style_reviews[('review', 'embedding')].tolist()).mean(axis=0)\n",
    "    rest_embedding = np.array(rest_reviews[('review', 'embedding')].tolist()).mean(axis=0)\n",
    "\n",
    "    # Take the difference between the style embedding and the rest embedding\n",
    "    style_diff = style_embedding - rest_embedding\n",
    "\n",
    "    # Get the top 10 features for the absolute difference\n",
    "    top_k_embeddings = np.argsort(np.abs(style_diff))[::-1][:top_k]\n",
    "    top_k_features = np.array(embedder.get_feature_names())[top_k_embeddings]\n",
    "\n",
    "    # Plot the top 10 differences in features for the style\n",
    "    colors = [\"red\" if style_diff[i] > 0 else \"blue\" for i in top_k_embeddings]\n",
    "\n",
    "    ax = axes[i // 3, i % 3]\n",
    "\n",
    "    sns.barplot(y=top_k_features, x=style_diff[top_k_embeddings], ax=ax, orient=\"h\", hue=colors)\n",
    "    ax.set_title(f\"{style}\")\n",
    "    ax.set_xlabel(\"Feature\")\n",
    "    ax.set_ylabel(\"Average Embedding\")\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an SVM to classify into the style or not\n",
    "\n",
    "style = \"English Bitter\"\n",
    "\n",
    "style_reviews = reviews[reviews[('beer', 'style')] == style]\n",
    "rest_reviews = reviews[reviews[('beer', 'style')] != style]\n",
    "\n",
    "# Create the data\n",
    "style_embeddings = np.array(style_reviews[('review', 'embedding')].tolist())\n",
    "rest_embeddings = np.array(rest_reviews[('review', 'embedding')].tolist())\n",
    "\n",
    "X = np.concatenate([style_embeddings, rest_embeddings])\n",
    "y = np.concatenate([np.ones(len(style_embeddings)), np.zeros(len(rest_embeddings))])\n",
    "\n",
    "# Split the data into train and test\n",
    "train_size = 0.8\n",
    "train_idx = int(len(X) * train_size)\n",
    "X_train, X_test = X[:train_idx], X[train_idx:]\n",
    "y_train, y_test = y[:train_idx], y[train_idx:]\n",
    "\n",
    "# Train the SVM\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the SVM\n",
    "print(f\"Train Accuracy: {svm.score(X_train, y_train)}\")\n",
    "print(f\"Test Accuracy: {svm.score(X_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
